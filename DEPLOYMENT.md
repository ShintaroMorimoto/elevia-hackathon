# Deployment Guide - Elevia OKR Application

This guide explains how to deploy the Elevia OKR application to Google Cloud Platform using **GitHub Actions CI/CD** with Terraform and automated container deployment.

## üöÄ CI/CD First Approach

This project uses **GitHub Actions for all deployments**. Manual commands are provided for reference only - all actual deployments should use the automated CI/CD pipeline.

## Prerequisites

Before deploying, ensure you have:

1. **Google Cloud Project** with billing enabled
2. **GitHub repository** for the code
3. **Local development environment** with:
   - Google Cloud SDK (`gcloud`)
   - Terraform (>= 1.0)
   - Node.js 20+
   - pnpm

## Infrastructure Overview

The deployment consists of:
- **Cloud SQL (PostgreSQL)** - Database with private IP
- **Cloud Run** - Application runtime with VPC access
- **VPC** - Private networking with connector
- **Artifact Registry** - Container images
- **Secret Manager** - Sensitive data (DB passwords, secrets)
- **GitHub Actions** - CI/CD pipeline with Workload Identity Federation

## Architecture

### Production Environment (Cloud Run)
- **Database Connection**: VPC direct connection to Cloud SQL private IP
- **Secret Management**: Secret Manager injection for DB_PASS and AUTH_SECRET
- **Security**: No exposed passwords, VPC-only database access

### Development Environment  
- **Database Connection**: Cloud SQL Proxy on localhost:5432
- **Configuration**: Individual environment variables from .env.local

## Step 1: Initial Setup

### 1.1 Clone and Configure

```bash
# Clone the repository
git clone <your-repo-url>
cd deploy-to-gcp

# Copy environment template
cp .env.template .env.local

# Edit .env.local with your values
```

### 1.2 Configure Environment Variables

Edit `.env.local`:

```bash
# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
GOOGLE_CLOUD_PROJECT_NUMBER=123456789012
WORKLOAD_IDENTITY_POOL=github-actions
WORKLOAD_IDENTITY_PROVIDER=github
GITHUB_REPO=your-repo-name
GITHUB_OWNER=your-github-username

# Database Configuration
# Note: CLOUD_SQL_CONNECTION_NAME will be generated by Terraform after deployment
DB_USER=elevia_user
DB_PASS=your-secure-database-password-min-8-chars
DB_NAME=elevia_db

# NextAuth Configuration (NextAuth v5 automatically detects URL)
AUTH_SECRET=your-32-char-secret-key

# AI Configuration (Vertex AI)
GOOGLE_VERTEX_PROJECT=your-project-id
GOOGLE_VERTEX_LOCATION=us-central1
```

### 1.3 Initialize Google Cloud Workload Identity (One-time Setup)

**Note**: This is a one-time setup that only needs to be run once per project.

```bash
# Make the init script executable and run
chmod +x ./scripts/init.sh && ./scripts/init.sh
```

This script configures:
- Workload Identity Federation for GitHub Actions
- **Minimal required APIs only** (Terraform will enable the rest to avoid permission conflicts)
- Service accounts and IAM permissions  
- GCS bucket for Terraform state management with versioning and lifecycle rules
- **Uniform Bucket Level Access (UBLA)** for Terraform state bucket (required for Terraform backend)

**The script is idempotent** - running it multiple times is safe.

**For fresh project deployments**: Ensure you have Project Owner or Editor permissions for the initial setup, as API enablement and Workload Identity Federation require elevated privileges.

## Step 2: Configure GitHub Repository

### 2.1 Set Repository Variables

In your GitHub repository, go to Settings > Secrets and variables > Actions, and add these **Variables**:

```
GOOGLE_CLOUD_PROJECT_ID=your-gcp-project-id
GOOGLE_CLOUD_PROJECT_NUMBER=123456789012
WORKLOAD_IDENTITY_POOL=github-actions
WORKLOAD_IDENTITY_PROVIDER=github
```

### 2.2 Set Repository Secrets

‚ö†Ô∏è **IMPORTANT**: Secrets must be set in the **"Terraform" Environment** (not Repository Secrets)

1. Go to Settings > Environments
2. Click on **"Terraform"** environment (create if it doesn't exist)
3. Add these **Environment secrets**:

```
AUTH_SECRET=your-nextauth-secret-here    # NextAuth v5 secret for session encryption
DB_USER=elevia_user
DB_PASS=your-secure-database-password
DB_NAME=elevia_db
AUTH_GOOGLE_ID=your-google-oauth-client-id    # Google OAuth client ID
AUTH_GOOGLE_SECRET=your-google-oauth-client-secret    # Google OAuth client secret
```

**Critical Notes**:
- ‚úÖ Use `AUTH_SECRET` (not `NEXTAUTH_SECRET`)
- ‚úÖ Avoid special characters like `/`, `"`, `'` in secret values
- ‚úÖ Set in "Terraform" Environment, not Repository Secrets
- ‚úÖ Must match the `environment: Terraform` setting in terraform.yml

**Note**: These values will be automatically stored in Secret Manager by Terraform and injected into Cloud Run at runtime. You don't need to manually create secrets in Google Cloud Console.

### ‚ö†Ô∏è Quick Configuration Checklist

Before running workflows, verify these critical settings:

**GitHub Repository Variables** ‚úÖ
```bash
# Verify with: gh api repos/:owner/:repo/actions/variables
GOOGLE_CLOUD_PROJECT_ID=your-project-id
GOOGLE_CLOUD_PROJECT_NUMBER=123456789012  
WORKLOAD_IDENTITY_POOL=github-actions
WORKLOAD_IDENTITY_PROVIDER=github
```

**‚ö†Ô∏è Common Configuration Pitfalls**:
- Ensure `WORKLOAD_IDENTITY_POOL=github-actions` (not `github-test`)
- Variable values must not contain leading/trailing spaces
- Use Repository Variables (not Environment Variables) for these settings

**GitHub Environment "Terraform" Secrets** ‚úÖ
```bash
# Verify with: gh api repos/:owner/:repo/environments/Terraform/secrets
AUTH_SECRET=your-secret-here    # NextAuth v5 secret
DB_USER=elevia_user
DB_PASS=your-password
DB_NAME=elevia_db
```

**Workload Identity Repository Setting** ‚úÖ
```bash
# Verify with: gcloud iam workload-identity-pools providers describe github ...
# Should show: assertion.repository=='YourUsername/your-actual-repo-name'
```

## Step 3: Setup GitHub Actions Workflows

The deployment is fully automated through GitHub Actions using **Direct Workload Identity Federation**. Once the repository variables and secrets are configured, deployments happen automatically on push to main branch.

### 3.1 GitHub Actions Workflows Created

**PR Validation Workflow (`.github/workflows/pr-validation.yml`)**:
- ‚úÖ **Early Feedback**: Fast quality checks on every pull request
- ‚úÖ **Comprehensive Testing**: Lint, type check, unit tests, application build
- ‚úÖ **Docker Build Validation**: Ensures Docker image builds successfully
- ‚úÖ **No Redundancy**: Single workflow for all PR validation needs

**Infrastructure Workflow (`.github/workflows/terraform.yml`)**:
- ‚úÖ **Direct Workload Identity Federation**: No service account needed for GitHub Actions authentication
- ‚úÖ **Terraform Plan on PRs**: Automatic plan comments on pull requests  
- ‚úÖ **Terraform Apply on Main**: Automatic infrastructure deployment on merge
- ‚úÖ **30-minute timeout**: Handles Cloud SQL creation time

**Deployment Workflow (`.github/workflows/deploy.yml`)**:
- ‚úÖ **Main Branch Only**: Triggers only on main branch push (no PR triggers)
- ‚úÖ **No Test Duplication**: Focuses solely on deployment activities
- ‚úÖ **Docker Build/Push**: Automatic container creation and push to Artifact Registry
- ‚úÖ **Cloud Run Deployment**: Zero-downtime rolling deployment with comprehensive environment configuration
- ‚úÖ **Environment Variable Management**: Proper handling of environment variables with `--update-env-vars` for AUTH_URL updates
- ‚úÖ **Vertex AI Integration**: Automatic configuration of Vertex AI environment variables for OKR generation
- ‚úÖ **Database Migration**: Automatic Drizzle migrations
- ‚úÖ **Direct WIF Authentication**: Secure authentication without service account keys

**Workflow Optimization Benefits**:
- ‚úÖ **No Duplication**: Each workflow has clear, separate responsibilities
- ‚úÖ **Fast PR Feedback**: Quality checks complete quickly without heavy deployment steps
- ‚úÖ **Resource Efficient**: Eliminates redundant test execution
- ‚úÖ **Clear Separation**: Validation vs. deployment concerns properly separated

### 3.2 Terraform Configuration (Automated)

Terraform variables are managed through the GitHub Actions workflow. The `terraform.tfvars` file is automatically generated from repository secrets and variables.

**Key Terraform Improvements Already Applied**:
- ‚úÖ **Timeout Configuration**: 30-minute timeouts for Cloud SQL operations
- ‚úÖ **Dependency Management**: Explicit dependencies prevent race conditions  
- ‚úÖ **API Corrections**: Uses correct `sqladmin.googleapis.com` API name
- ‚úÖ **Direct Workload Identity Federation**: No service account keys for GitHub Actions

## Step 4: Deploy via GitHub Actions

### 4.1 Automated Deployment Process

The deployment process is **fully automated**:

1. **Push to main branch** triggers the deployment workflow
2. **GitHub Actions automatically**:
   - Runs tests and linting
   - Deploys infrastructure via Terraform (if changes detected)
   - Builds and pushes Docker image to Artifact Registry
   - Deploys to Cloud Run with Secret Manager integration
   - Runs database migrations automatically

### 4.2 Deployment Workflow Features

**Infrastructure Management**:
- ‚úÖ **Direct Workload Identity Federation**: Secure authentication without service account keys
- ‚úÖ Terraform plan on pull requests (with plan comments)
- ‚úÖ Terraform apply on main branch merges
- ‚úÖ 30-minute timeout handling for Cloud SQL
- ‚úÖ Automatic dependency resolution

**Application Deployment**:
- ‚úÖ **Direct WIF Authentication**: No service account keys needed
- ‚úÖ Full CI pipeline (lint, test, build)
- ‚úÖ Automated Docker build and push to Artifact Registry
- ‚úÖ Zero-downtime Cloud Run deployment
- ‚úÖ Automatic database migrations with Drizzle
- ‚úÖ Secret Manager integration (no exposed credentials)
- ‚úÖ VPC-only database access (production security)

**No manual intervention required** - the entire process is automated from code push to production deployment.

## Step 5: Database Setup (Automated)

### 5.1 Production Database Configuration

**Database setup is fully automated** through the GitHub Actions deployment:

- ‚úÖ Cloud SQL PostgreSQL instance creation (with 30-minute timeout)
- ‚úÖ Database and user creation via Terraform
- ‚úÖ VPC-only access (no public IP)
- ‚úÖ Secret Manager integration for credentials
- ‚úÖ Automatic migrations during deployment

### 5.2 Local Development Setup

For local development, connect to the Cloud SQL instance:

```bash
# Install Cloud SQL Proxy
gcloud components install cloud-sql-proxy

# Get connection name from deployment outputs
terraform output cloud_sql_connection_name

# Start proxy for local development
cloud_sql_proxy -instances=YOUR_CONNECTION_NAME=tcp:5432

# Run development setup
pnpm run db:generate
pnpm run db:migrate
pnpm run dev
```

**Environment Detection**:
- **Development**: Uses Cloud SQL Proxy on localhost:5432
- **Production**: Uses VPC direct connection with Secret Manager

## Step 6: Verify Deployment (Automated)

### 6.1 Deployment Verification

**GitHub Actions automatically verifies**:
- ‚úÖ Infrastructure deployment status
- ‚úÖ Docker image build and push
- ‚úÖ Cloud Run service health
- ‚úÖ Database connectivity
- ‚úÖ Application startup and readiness

### 6.2 Access Your Application

1. **Cloud Run URL**: Automatically provided in GitHub Actions logs
2. **Application Health**: Built-in health checks verify deployment
3. **Monitoring**: Cloud Logging and Monitoring automatically configured

**Manual verification commands** (optional):
```bash
# View deployment outputs
terraform output cloud_run_url

# Check service status
gcloud run services list --platform=managed

# View application logs
gcloud logs read --service=elevia --platform=managed
```

## Step 7: Custom Domain (Optional)

### 7.1 Configure Domain Mapping

```bash
# Map custom domain to Cloud Run
gcloud run domain-mappings create \
  --service=elevia \
  --domain=your-domain.com \
  --region=asia-northeast1
```

### 7.2 Update Environment Variables

NextAuth v5 automatically detects the domain from the request, no additional configuration needed.

## Monitoring and Maintenance

### Database Backups

Cloud SQL automatically creates daily backups and supports point-in-time recovery.

### Logs and Monitoring

- **Application logs**: Available in Cloud Logging
- **Metrics**: Available in Cloud Monitoring
- **Error tracking**: Available in Error Reporting

### Updating the Application

1. Make code changes
2. Push to main branch
3. GitHub Actions will automatically deploy

### Scaling

Cloud Run automatically scales based on traffic. Adjust `max_instances` in Terraform if needed.

## Troubleshooting

### üîß CI/CD Workflow Architecture and Troubleshooting

#### Critical Design Decision: Responsibility Separation

**Infrastructure vs Application Management:**
- **Terraform (Infrastructure Workflow)**: Manages VPC, Cloud SQL, VPC connectors, service accounts, secrets
- **GitHub Actions (Deployment Workflow)**: Manages Cloud Run service, Docker images, application deployment

**Why This Separation Matters:**
- ‚úÖ **Prevents Resource Conflicts**: Each workflow manages distinct resources
- ‚úÖ **Enables Independent Updates**: Infrastructure changes don't require redeployment
- ‚úÖ **Supports Development Workflow**: Application updates happen without infrastructure changes
- ‚úÖ **Avoids 409 Conflicts**: No duplicate resource management

#### Resource Conflict Resolution Experience

**Issue**: Both Terraform and GitHub Actions workflows trying to manage the same Cloud Run service.

**Error Pattern**:
```
Error: Error creating Service: googleapi: Error 409: Resource 'elevia' already exists.
```

**Root Cause**: Overlapping responsibility between infrastructure and application workflows.

**Solution Applied**: 
- Removed `google_cloud_run_v2_service` and `google_cloud_run_service_iam_member` from Terraform
- Updated outputs to remove Cloud Run URLs (managed by deployment workflow)
- Clear separation: Terraform provides infrastructure, deployment workflow uses it

**Prevention**: Always define clear boundaries between infrastructure and application management.

#### VPC Access Connector Configuration Issues

**Issue**: VPC Access Connector creation failures due to CIDR range conflicts.

**Error Patterns**:
```
Error: Invalid IP CIDR range was provided. It conflicts with an existing subnetwork.
Error: Error 409: Requested entity already exists
```

**Root Cause Analysis**:
1. **Subnet vs ip_cidr_range confusion**: VPC Access Connector can either:
   - Use `ip_cidr_range` to auto-create a subnet
   - Use `subnet` parameter to reference existing subnet
2. **Error state persistence**: Deleted connectors may remain in ERROR state
3. **CIDR range conflicts**: Multiple subnets trying to use same IP range

**Solution Applied**:
```hcl
# ‚ùå Wrong - causes CIDR conflicts
resource "google_vpc_access_connector" "connector" {
  name          = "elevia-connector-v2"
  region        = var.region
  network       = google_compute_network.vpc_network.name
  ip_cidr_range = "10.9.0.0/28"  # Conflicts with existing subnet
}

# ‚úÖ Correct - uses existing subnet
resource "google_vpc_access_connector" "connector" {
  name   = "elevia-connector-v2"
  region = var.region
  subnet {
    name = google_compute_subnetwork.vpc_connector_subnet.name
  }
}
```

**Debugging Commands**:
```bash
# Check existing VPC connectors and their state
gcloud compute networks vpc-access connectors list --region=asia-northeast1

# Check subnet CIDR ranges
gcloud compute networks subnets list --filter="ipCidrRange:10.9.0.0/28"

# Delete ERROR state connectors before retry
gcloud compute networks vpc-access connectors delete elevia-connector-v2 --region=asia-northeast1 --quiet
```

#### Workload Identity Federation Permission Issues

**Issue**: GitHub Actions authentication succeeds but resource operations fail with permission errors.

**Error Patterns**:
```
Permission 'iam.serviceAccounts.create' denied
Permission 'vpcaccess.connectors.create' denied
Permission 'secretmanager.secrets.create' denied
```

**Root Cause**: Insufficient IAM roles granted to workload identity pools.

**Required Roles for Infrastructure Management**:
```bash
# Core infrastructure roles
"roles/cloudsql.admin"
"roles/run.admin" 
"roles/storage.admin"
"roles/compute.admin"
"roles/iam.serviceAccountAdmin"
"roles/secretmanager.admin"
"roles/artifactregistry.admin"

# Network and VPC roles
"roles/servicenetworking.networksAdmin"
"roles/vpcaccess.admin"

# Permission management roles
"roles/resourcemanager.projectIamAdmin"
"roles/iam.serviceAccountUser"
"roles/iam.serviceAccountTokenCreator"

# API enablement roles
"roles/serviceusage.serviceUsageAdmin"
"roles/serviceusage.serviceUsageConsumer"
```

**Fresh Project Deployment Strategy**:
```bash
# init.sh enables minimal APIs to avoid permission conflicts
MINIMAL_APIS=(
    "iamcredentials.googleapis.com"
    "cloudresourcemanager.googleapis.com"
)

# Terraform handles remaining API enablement
# This prevents permission errors when init.sh lacks API enablement permissions
```

**Multiple Pool Management**:
```bash
# Both pools need permissions due to different environment configurations
- github-actions pool (deployment workflow)
- github-test pool (Terraform workflow)
```

**Solution in init.sh**:
```bash
# Updated init.sh automatically grants required roles to both pools
for role in "roles/cloudsql.admin" "roles/run.admin" "roles/compute.admin" \
           "roles/iam.serviceAccountAdmin" "roles/secretmanager.admin" \
           "roles/vpcaccess.admin" "roles/servicenetworking.networksAdmin"; do
    # Grant to workload identity pool
    gcloud projects add-iam-policy-binding $PROJECT_ID \
        --member="principalSet://iam.googleapis.com/projects/$PROJECT_NUMBER/locations/global/workloadIdentityPools/$WORKLOAD_IDENTITY_POOL/attribute.repository/$GITHUB_OWNER/$GITHUB_REPO" \
        --role="$role"
done
```

### ‚ö†Ô∏è Critical GitHub Actions Configuration Issues

#### 1. GitHub Environment Variables Not Recognized

**Issue**: GitHub Actions variables appear to be set but are empty in workflows.

**Root Cause**: GitHub has multiple places to store variables:
- **Repository Variables** (Settings > Secrets and variables > Actions > Variables tab)
- **Environment Variables** (Settings > Environments > [Environment Name] > Environment variables)

**Solution**: 
- ‚úÖ **Ensure variables are set in the correct Environment**
- The workflow uses `environment: Terraform` (line 26 in terraform.yml)
- Variables must be set in the **"Terraform" Environment**, not "Configure Terraform" or Repository Variables
- **Verification**: Use `gh api repos/:owner/:repo/environments/Terraform/variables` to check

```bash
# Check which environments exist
gh api repos/:owner/:repo/environments

# Check variables in specific environment  
gh api repos/:owner/:repo/environments/Terraform/variables

# Should show your 4 required variables
```

**Required Variables in "Terraform" Environment**:
```
GOOGLE_CLOUD_PROJECT_ID=your-project-id
GOOGLE_CLOUD_PROJECT_NUMBER=123456789012
WORKLOAD_IDENTITY_POOL=github-test
WORKLOAD_IDENTITY_PROVIDER=github
```

#### 2. Workload Identity Federation Permission Errors

**Issue**: Authentication works but gets "unauthorized_client" or "repository not allowed" errors.

**Root Cause**: 
- Wrong repository name in Workload Identity Provider attribute condition
- Old permissions from previous repository names
- `init.sh` script has a bug in permission checking logic

**Solutions**:

**Check Current Attribute Condition**:
```bash
gcloud iam workload-identity-pools providers describe github \
  --workload-identity-pool=github-test \
  --location=global \
  --project=sandbox-morimoto-s1 \
  --format="value(attributeCondition)"
```

**Update Repository Name if Incorrect**:
```bash
gcloud iam workload-identity-pools providers update-oidc github \
  --workload-identity-pool=github-test \
  --location=global \
  --project=sandbox-morimoto-s1 \
  --attribute-condition="assertion.repository=='YourGitHubUsername/your-repo-name'"
```

**Re-run init.sh after fixing the script**:
```bash
# The init.sh script has been fixed for permission checking
./scripts/init.sh
```

#### 3. Secret Manager Variable Name Mismatches

**Issue**: `nextauth_secret = ""` (empty) in terraform.tfvars despite secrets being set.

**Root Causes**:
- Variable name mismatch: `NEXTAUTH_SECRET` vs `AUTH_SECRET`
- HEREDOC vs echo command variable expansion issues
- Special characters (like `/`) in secret values causing parsing errors

**Solutions**:

**Correct Secret Names** (set these in GitHub Environment "Terraform" Secrets):
```
AUTH_SECRET=your-nextauth-secret-here  # NextAuth v5 secret
DB_USER=elevia_user
DB_PASS=your-secure-password
DB_NAME=elevia_db
AUTH_GOOGLE_ID=your-google-oauth-client-id  # Google OAuth client ID
AUTH_GOOGLE_SECRET=your-google-oauth-client-secret  # Google OAuth client secret
```

**Avoid Special Characters in Secrets**:
- Don't use `/`, `"`, `'`, `\` in AUTH_SECRET values
- Use base64 encoded values if needed: `openssl rand -base64 32`

#### 4. Terraform State Bucket Configuration Issues

**Issue**: "bucket doesn't exist" or "Uniform Bucket Level Access be enabled" errors during terraform init.

**Root Causes**: 
1. **Naming convention mismatch** between init.sh and deploy.yml:
   - `init.sh` creates: `${PROJECT_ID}-terraform-state`
   - `deploy.yml` initially expected: `terraform-state-${PROJECT_ID}`
2. **Missing Uniform Bucket Level Access (UBLA)** requirement for Workload Identity Federation

**Solutions**:

**Fix Bucket Naming**:
```yaml
# ‚ùå Wrong - inconsistent with init.sh
terraform init \
  -backend-config="bucket=terraform-state-${{ vars.GOOGLE_CLOUD_PROJECT_ID }}" \

# ‚úÖ Correct - matches init.sh pattern
terraform init \
  -backend-config="bucket=${{ vars.GOOGLE_CLOUD_PROJECT_ID }}-terraform-state" \
```

**Enable UBLA for Workload Identity Federation**:
```bash
# Required for Workload Identity Federation authentication
gsutil uniformbucketlevelaccess set on gs://${PROJECT_ID}-terraform-state
```

**Critical for Fresh Projects**: UBLA (Uniform Bucket Level Access) is **mandatory** for Terraform backends with Workload Identity Federation. The error "Uniform Bucket Level Access be enabled" indicates this is missing.

**Fresh Project Deployment Notes**:
- init.sh automatically enables UBLA during bucket creation
- For existing buckets without UBLA, enable it manually before running Terraform workflows
- UBLA cannot be disabled once enabled (irreversible change)

**Prevention**: Always verify bucket naming consistency and UBLA configuration between init.sh and CI/CD workflows.

#### 5. Terraform Import Blocks for Fresh Projects

**Issue**: Terraform fails with "Cannot import non-existent remote object" errors during fresh project deployment.

**Error Pattern**:
```
Error: Cannot import non-existent remote object
‚îÇ   with google_service_account.cloud_run_sa,
‚îÇ   on main.tf line 205, in import:
‚îÇ   205: import {
‚îÇ   206:   to = google_service_account.cloud_run_sa
‚îÇ   207:   id = "projects/${var.project_id}/serviceAccounts/${var.app_name}-run-sa@${var.project_id}.iam.gserviceaccount.com"
‚îÇ   208: }
```

**Root Cause**: Import blocks are designed for importing existing resources into Terraform state. For completely fresh project deployments, these resources don't exist yet.

**Solution for Fresh Projects**:
The Terraform configuration includes commented-out import blocks for fresh deployments:
```hcl
# Import existing service account if it exists (commented out for new projects)
# import {
#   to = google_service_account.cloud_run_sa
#   id = "projects/${var.project_id}/serviceAccounts/${var.app_name}-run-sa@${var.project_id}.iam.gserviceaccount.com"
# }
```

**When to Use Import Blocks**:
- ‚úÖ **Existing Projects**: When migrating existing Google Cloud resources to Terraform management
- ‚ùå **Fresh Projects**: When deploying to a completely new project for the first time

**Prevention Strategy**:
- Keep import blocks commented out by default
- Only uncomment when specifically importing existing resources
- Document which import blocks are for migration vs fresh deployment scenarios

#### 6. Terraform Format Issues with Generated Files

**Issue**: `terraform fmt -check` fails with "Missing newline after argument".

**Root Causes**:
- Generated terraform.tfvars missing final newline
- Single quotes preventing variable expansion in echo commands
- HEREDOC not handling special characters properly

**Solution**: Fixed in terraform.yml to:
- Use double quotes with escaped inner quotes
- Run `terraform fmt` after file generation
- Use echo commands instead of HEREDOC

#### 6. Branch Protection Rules and GitHub Pro Requirements

**Issue**: Cannot set up branch protection rules to prevent merging when workflows fail.

**Root Cause**: GitHub branch protection features require:
- **GitHub Pro subscription** for private repositories
- **Public repository** for free accounts

**Solutions**:

**Option A: Manual Process** (No GitHub Pro required):
1. Always check GitHub Actions status before merging PRs
2. Look for green checkmarks on all required workflows
3. Only merge when all checks pass

**Option B: Repository Settings** (Requires GitHub Pro or public repo):
1. Go to Settings > Branches
2. Add rule for `main` branch:
   - ‚úÖ Require status checks to pass before merging
   - ‚úÖ Require branches to be up to date before merging
   - Select required checks: `Terraform Infrastructure`, `Pull Request Validation`
   - ‚úÖ Require pull request reviews before merging

**Option C: GitHub Actions Auto-merge** (Alternative):
```yaml
# Add to workflow to enable auto-merge only when all checks pass
- name: Enable auto-merge
  if: github.event_name == 'pull_request'
  run: gh pr merge --auto --merge "${{ github.event.pull_request.number }}"
  env:
    GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

**Verification Commands**:
```bash
# Check current branch protection status
gh api repos/:owner/:repo/branches/main/protection

# List all workflow runs for a PR
gh run list --branch=your-pr-branch

# Check workflow status
gh run view --log
```

### üöÄ Fresh Project Deployment Checklist

Based on lessons learned from deploying to completely new Google Cloud projects:

#### Pre-Deployment Verification
- ‚úÖ **Project Owner/Editor permissions** for initial setup
- ‚úÖ **BUCKET_NAME in .env.local** matches project-specific naming convention
- ‚úÖ **GitHub Repository Variables** set correctly (no spaces, correct pool name)
- ‚úÖ **Terraform import blocks commented out** for fresh deployments
- ‚úÖ **init.sh API strategy** (minimal APIs only, let Terraform handle the rest)

#### Common Fresh Project Pitfalls
- ‚ùå **UBLA not enabled** ‚Üí Terraform backend authentication fails
- ‚ùå **Import blocks active** ‚Üí "Cannot import non-existent remote object" errors
- ‚ùå **API enablement conflicts** ‚Üí Permission denied errors in init.sh
- ‚ùå **GitHub Variable spaces** ‚Üí Empty variable values in workflows
- ‚ùå **Wrong WORKLOAD_IDENTITY_POOL name** ‚Üí "github-test" vs "github-actions" mismatch

#### Successful Fresh Deployment Flow
1. **Configure .env.local** with project-specific values
2. **Run init.sh** (enables minimal APIs + WIF setup)
3. **Set GitHub Repository Variables** (verify no spaces)
4. **Commit/push to trigger CI/CD** (Terraform applies automatically)
5. **Monitor workflows** for UBLA, import blocks, API enablement issues

### Common Issues

1. **Permission Errors During Terraform Apply**
   
   **Error**: `Permission denied to enable service [cloudsql.googleapis.com]` or `Service 'cloudsql.googleapis.com' is an internal service; it cannot be used outside of its own organization.`
   
   **Cause**: This error occurs due to organization policy restrictions that limit which services can be enabled in the project.
   
   **Solutions**:
   
   **Option A: Contact Organization Administrator**
   - Contact your Google Cloud organization administrator to:
     - Enable Cloud SQL API at the organization level
     - Remove organization policy constraints that prevent API enablement
     - Grant appropriate permissions for the sandbox project
   
   **Option B: Use a Personal Google Cloud Project**
   - Create a new Google Cloud project using your personal Google account
   - Use that project for development/testing purposes
   - Update `.env.local` and `terraform.tfvars` with the new project ID
   
   **Option C: Alternative Architecture**
   - Modify the Terraform configuration to use external database services (like Supabase or AWS RDS)
   - Update the application to connect to external databases instead of Cloud SQL
   
   **Manual verification of current APIs**:
   ```bash
   # Check which APIs are currently enabled
   gcloud services list --enabled --project=sandbox-morimoto-s1
   
   # Check organization policies that might be blocking API enablement
   gcloud resource-manager org-policies list --project=sandbox-morimoto-s1
   ```
   
   **If APIs can be enabled manually through Console**:
   - Go to Google Cloud Console ‚Üí APIs & Services ‚Üí Library
   - Search for and enable each required API manually:
     - Cloud SQL Admin API
     - Compute Engine API
     - Cloud Run API
     - Artifact Registry API
     - VPC Access API
     - Service Networking API
   - Then retry: `terraform apply`

2. **Database Connection Errors**
   - **Production**: Check VPC connector configuration and Secret Manager access
   - **Development**: Ensure Cloud SQL Proxy is running on localhost:5432
   - Verify Cloud SQL instance is running: `gcloud sql instances list`
   - Check logs: `gcloud logs read --service=elevia --platform=managed`

2. **Secret Manager Issues**
   - Verify secrets exist: `gcloud secrets list`
   - Check Cloud Run service account has `secretmanager.secretAccessor` role
   - Ensure DB_PASS and AUTH_SECRET are properly set in Terraform

3. **Environment Detection Issues**
   - Check `K_SERVICE` environment variable is set in Cloud Run
   - Verify `NODE_ENV=production` in Cloud Run
   - Review database connection logs in Cloud Logging

4. **Build Failures**
   - Check Docker build logs in GitHub Actions
   - Verify all dependencies are installed (including @google-cloud/cloud-sql-connector)
   - Check for TypeScript/linting errors

5. **Permission Errors**
   - Verify Workload Identity Federation setup
   - Check service account permissions
   - Ensure GitHub variables/secrets are set correctly

### CI/CD Troubleshooting Best Practices

#### 7. Systematic CI/CD Debugging Approach

When CI/CD fails, follow this systematic debugging approach:

**Step 1: Identify the Failing Stage**
```bash
# Check recent workflow runs
gh run list --limit 10

# Get specific run details
gh run view <run-id>

# View logs for failed run
gh run view <run-id> --log
```

**Step 2: Analyze Error Patterns**
- **Authentication errors**: Check Workload Identity Federation setup
- **Resource not found**: Verify resource naming consistency
- **Permission denied**: Check IAM roles and bindings
- **Timeout errors**: Verify timeout settings (especially for Cloud SQL)

**Step 3: Common Debugging Commands**
```bash
# Check workflow file syntax
cat .github/workflows/deploy.yml | grep -A5 -B5 "bucket"

# Verify GitHub repository variables
gh variable list

# Verify GitHub repository secrets
gh secret list

# Check Google Cloud authentication
gcloud auth list
gcloud config get-value project

# Verify init.sh setup
ls -la gs://sandbox-morimoto-s1-terraform-state/
```

**Step 4: Fix and Test Cycle**
1. Identify root cause from logs
2. Fix configuration inconsistencies
3. Commit changes with descriptive message
4. Monitor new workflow execution
5. Repeat if necessary

**Step 5: Prevention Measures**
- Verify naming conventions between init.sh and workflows
- Test workflows in feature branches when possible
- Use repository variables consistently
- Document configuration dependencies

### Logs and Debugging

```bash
# View Cloud Run logs (shows database connection attempts)
gcloud logs read --service=elevia --platform=managed

# View recent logs with filter
gcloud logs read --service=elevia --platform=managed --limit=50 --format="table(timestamp,severity,textPayload)"

# Check Secret Manager access
gcloud secrets versions access latest --secret=elevia-db-password
gcloud secrets versions access latest --secret=elevia-nextauth-secret

# View Cloud SQL logs
gcloud sql operations list --instance=elevia-postgres-xxxx

# Test VPC connectivity from Cloud Run
gcloud run jobs create test-connection \
  --image=gcr.io/google.com/cloudsdktool/cloud-sdk:latest \
  --task-timeout=300 \
  --command=sh \
  --args="-c","apt-get update && apt-get install -y postgresql-client && psql postgresql://USER:PASS@PRIVATE_IP:5432/DATABASE -c 'SELECT NOW();'"

# View Terraform state
terraform show

# Monitor live workflow execution
gh run watch <run-id>

# Check workflow file differences
git diff HEAD~1 .github/workflows/deploy.yml
```

## Security Considerations

- **Secret Management**: Database passwords and NextAuth secrets stored in Google Secret Manager
- **Network Security**: Cloud SQL uses private IP with VPC-only access
- **No Service Account Keys**: Workload Identity Federation eliminates long-lived keys
- **Runtime Security**: Secrets injected at runtime, never stored in code or containers
- **HTTPS Only**: All traffic to Cloud Run is automatically HTTPS
- **IAM Principle of Least Privilege**: Cloud Run service account has minimal required permissions
- **Regular Updates**: Automated security updates via CI/CD pipeline

### Secret Manager Security
- Secrets are encrypted at rest and in transit
- Access logs available for audit
- Version management for secret rotation
- Cloud Run service account requires explicit `secretmanager.secretAccessor` permission

## Cost Optimization

- Cloud Run scales to zero when not in use
- Cloud SQL uses smallest instance size (db-f1-micro) by default
- Terraform state includes deletion protection for production data
- Consider upgrading to larger instances for production workloads

## Environment Configuration Details

### Production Environment Variables (Cloud Run)

The following environment variables are automatically configured by Terraform:

```bash
# Set by Terraform
NODE_ENV=production
CLOUD_SQL_CONNECTION_NAME=project:region:instance  # From terraform output
DB_NAME=elevia_db
DB_USER=elevia_user
AUTH_URL=https://your-cloud-run-url  # Updated automatically by deployment workflow

# Vertex AI Configuration
GOOGLE_VERTEX_PROJECT=your-project-id  # For AI-powered OKR generation
GOOGLE_VERTEX_LOCATION=us-central1

# Injected from Secret Manager
DB_PASS=***  # From Secret Manager secret: elevia-db-password
AUTH_SECRET=***  # From Secret Manager secret: elevia-nextauth-secret
AUTH_GOOGLE_ID=***  # From Secret Manager secret: elevia-google-oauth-client-id
AUTH_GOOGLE_SECRET=***  # From Secret Manager secret: elevia-google-oauth-client-secret

# Cloud Run specific
K_SERVICE=elevia  # Automatically set by Cloud Run
```

### Development Environment Variables (.env.local)

```bash
# Required for development
CLOUD_SQL_CONNECTION_NAME=project:region:instance  # From terraform output
DB_USER=elevia_user
DB_PASS=your-local-password  # Same as Terraform variable
DB_NAME=elevia_db
NEXTAUTH_URL=http://localhost:3000
AUTH_SECRET=your-32-char-secret  # Same as Terraform variable

# Optional
DB_HOST=127.0.0.1  # For Cloud SQL Proxy
DB_PORT=5432
```

### Environment Detection Logic

The application automatically detects the environment:

```typescript
const isProduction = process.env.NODE_ENV === 'production';
const isCloudRun = process.env.K_SERVICE !== undefined;

if (isProduction && isCloudRun) {
  // Use VPC direct connection
} else {
  // Use Cloud SQL Connector
}
```

For additional support, refer to the Google Cloud documentation or open an issue in the repository.

---

## Summary: CI/CD-First Deployment Architecture

### üéØ Design Philosophy

This deployment uses a **CI/CD-first approach** where:

- ‚úÖ **Infrastructure as Code**: Terraform with proper timeout and dependency management
- ‚úÖ **Automated Deployment**: GitHub Actions handles all deployment steps
- ‚úÖ **Security**: Direct Workload Identity Federation (no service account keys)
- ‚úÖ **Zero-Downtime**: Cloud Run with rolling deployments
- ‚úÖ **Production-Ready**: VPC networking, Secret Manager, private databases

### üîß Technical Improvements Applied

**Terraform Configuration**:
- **30-minute timeouts** for Cloud SQL operations (handles 15-20 minute creation time)
- **Explicit dependencies** prevent resource creation race conditions
- **Correct API names** (`sqladmin.googleapis.com` instead of `cloudsql.googleapis.com`)
- **Direct Workload Identity Federation** for secure GitHub Actions authentication

**Application Architecture**:
- **Cloud Run** with VPC connector for private database access
- **Secret Manager** for credential management (no environment variables)
- **Artifact Registry** for container images
- **Automatic scaling** from 0 to 10 instances

### üöÄ Next Steps

1. **Setup GitHub Actions workflows** (see next section)
2. **Push to main branch** to trigger automated deployment
3. **Monitor deployment** through GitHub Actions logs
4. **Access application** via automatically generated Cloud Run URL

The entire infrastructure and application stack deploys automatically with a single git push.

## üîÑ Zero-to-Production Deployment Checklist

### Prerequisites Verification

Before starting a fresh deployment, verify these prerequisites:

```bash
# 1. Verify Google Cloud Project Access
gcloud auth list
gcloud config get-value project
gcloud services list --enabled --filter="name:compute.googleapis.com"

# 2. Verify GitHub Repository Access
gh auth status
gh repo view

# 3. Verify Local Environment
terraform --version  # Should be >= 1.0
node --version       # Should be >= 20
pnpm --version       # Package manager
```

### Step-by-Step Fresh Deployment Process

#### Phase 1: Initial Setup (One-time per project)

1. **Clone and Environment Setup**:
   ```bash
   git clone <your-repo-url>
   cd elevia-hackathon
   cp .env.template .env.local
   # Edit .env.local with your project values
   ```

2. **Run Initial Setup Script**:
   ```bash
   chmod +x ./scripts/init.sh
   ./scripts/init.sh
   ```
   **What this does**: Creates workload identity pools, grants IAM permissions, creates Terraform state bucket

3. **Configure GitHub Repository Variables** (Settings > Secrets and variables > Actions):
   ```
   GOOGLE_CLOUD_PROJECT_ID=your-project-id
   GOOGLE_CLOUD_PROJECT_NUMBER=123456789012
   WORKLOAD_IDENTITY_POOL=github-actions  # For deployment workflow
   WORKLOAD_IDENTITY_PROVIDER=github
   ```

4. **Configure GitHub Environment Secrets** (Settings > Environments > Terraform):
   ```
   AUTH_SECRET=your-32-char-secret
   DB_USER=elevia_user
   DB_PASS=your-secure-password
   DB_NAME=elevia_db
   ```

#### Phase 2: Infrastructure Deployment

5. **Create Terraform Environment in GitHub**:
   - Go to Settings > Environments
   - Create environment named "Terraform" (exact case-sensitive match)
   - Add environment variables (same as repository variables above)
   - Add environment secrets (as listed above)

6. **Trigger Infrastructure Deployment**:
   ```bash
   # Make any change to terraform/ directory to trigger workflow
   echo "# Infrastructure deployment $(date)" >> terraform/main.tf
   git add terraform/main.tf
   git commit -m "Trigger infrastructure deployment"
   git push origin main
   ```

7. **Monitor Infrastructure Workflow**:
   ```bash
   gh run list --workflow="Terraform Infrastructure"
   gh run watch <run-id>
   ```

#### Phase 3: Application Deployment

8. **Verify Infrastructure Outputs**:
   ```bash
   # Check that infrastructure deployment succeeded
   gh run list --workflow="Terraform Infrastructure" --limit 1
   # Should show "completed success"
   ```

9. **Application Deployment** (automatic):
   - Build and Deploy workflow triggers automatically after infrastructure
   - Monitor deployment: `gh run list --workflow="Build and Deploy to Cloud Run"`

10. **Verify Deployment Success**:
    ```bash
    # Check Cloud Run service
    gcloud run services list --platform=managed --region=asia-northeast1
    
    # Check infrastructure components
    gcloud compute networks vpc-access connectors list --region=asia-northeast1
    gcloud sql instances list
    
    # Get application URL
    gcloud run services describe elevia --region=asia-northeast1 --format="value(status.url)"
    ```

### Reproducibility Guarantees

**‚úÖ Infrastructure Reproducibility**:
- Terraform state stored in GCS with versioning
- All resource names use consistent naming patterns
- Import blocks handle existing resources gracefully
- Explicit dependencies prevent race conditions

**‚úÖ Application Reproducibility**:
- Docker images tagged with git SHA
- Environment configuration managed through Secret Manager
- Database migrations run automatically
- Zero-downtime rolling deployments

**‚úÖ Configuration Reproducibility**:
- All configuration stored in repository
- init.sh script is idempotent (safe to run multiple times)
- Clear separation between infrastructure and application workflows

### Troubleshooting Fresh Deployments

If deployment fails on a fresh project:

1. **Permission Issues**: Re-run `./scripts/init.sh` to ensure all IAM roles are granted
2. **GitHub Configuration**: Verify environment variables are in "Terraform" environment, not repository variables
3. **Resource Conflicts**: Use `gcloud` commands to check for existing resources with same names
4. **API Enablement**: Some organizations may require manual API enablement through Console

#### ‚ö†Ô∏è Critical Post-Deployment Issues

#### Environment Variable Overwrite in Cloud Run Updates

**Issue**: Cloud Run service loses all existing environment variables when updating AUTH_URL.

**Symptoms**:
```
Error: DB_USER environment variable not set
Error: CLOUD_SQL_CONNECTION_NAME environment variable not set
```

**Root Cause**: Using `--set-env-vars` instead of `--update-env-vars` in the deployment workflow overwrites all existing environment variables when updating AUTH_URL.

**Critical Fix Applied**:
```yaml
# ‚ùå Wrong - overwrites all existing environment variables
gcloud run services update ${{ env.SERVICE_NAME }} \
  --region=${{ env.REGION }} \
  --set-env-vars="AUTH_URL=${{ steps.deploy-url.outputs.url }}" \
  --quiet

# ‚úÖ Correct - preserves existing environment variables
gcloud run services update ${{ env.SERVICE_NAME }} \
  --region=${{ env.REGION }} \
  --update-env-vars="AUTH_URL=${{ steps.deploy-url.outputs.url }}" \
  --quiet
```

**Impact**: This fix prevents the loss of critical environment variables like NODE_ENV, DB_USER, CLOUD_SQL_CONNECTION_NAME, etc., ensuring the application continues to function after AUTH_URL updates.

**Prevention**: Always use `--update-env-vars` for single variable updates and `--set-env-vars` only for initial deployment or complete environment replacement.

#### Vertex AI Configuration for OKR Generation

**Requirement**: The application requires Vertex AI access for AI-powered OKR generation and conversation features.

**Environment Variables Required**:
```bash
# Add to deployment workflow
--set-env-vars="GOOGLE_VERTEX_PROJECT=${{ env.PROJECT_ID }}" \
--set-env-vars="GOOGLE_VERTEX_LOCATION=us-central1" \
```

**Service Account Permissions Required**:
```bash
# Add to init.sh or manually grant
gcloud projects add-iam-policy-binding $PROJECT_ID \
  --member="serviceAccount:elevia-run-sa@$PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/aiplatform.user"
```

**Verification**:
```bash
# Check Cloud Run environment variables include Vertex AI configuration
gcloud run services describe elevia --region=asia-northeast1 --format="export" | grep -i "VERTEX"

# Verify service account has Vertex AI permissions
gcloud projects get-iam-policy $PROJECT_ID --flatten="bindings[].members" --filter="bindings.members:elevia-run-sa@$PROJECT_ID.iam.gserviceaccount.com"
```

#### Cloud Run Service Environment Variable Configuration

**Issue**: Cloud Run service deploys successfully but application fails to start with environment variable errors.

**Symptoms**:
```
Error: DB_USER environment variable not set
cloudSqlConnectionName: undefined
```

**Root Cause**: The deployment workflow creates a basic Cloud Run service but doesn't configure the necessary environment variables for database connectivity and application configuration.

**Solution**: The deployment workflow must include comprehensive environment variable configuration:

```bash
gcloud run deploy $SERVICE_NAME \
  --image=$IMAGE_TAG \
  --region=$REGION \
  --platform=managed \
  --allow-unauthenticated \
  --service-account=elevia-run-sa@$PROJECT_ID.iam.gserviceaccount.com \
  --set-env-vars="NODE_ENV=production" \
  --set-env-vars="CLOUD_SQL_CONNECTION_NAME=$CLOUD_SQL_CONNECTION" \
  --set-env-vars="DB_NAME=elevia_db" \
  --set-env-vars="DB_USER=elevia_user" \
  --set-secrets="DB_PASS=elevia-db-password:latest" \
  --set-secrets="AUTH_SECRET=elevia-nextauth-secret:latest" \
  --vpc-connector=elevia-connector-v2 \
  --vpc-egress=private-ranges-only \
  --timeout=300 \
  --memory=1Gi \
  --cpu=1 \
  --max-instances=10
```

**Prevention Checklist**:
- ‚úÖ Verify environment variables are set in Cloud Run service
- ‚úÖ Confirm VPC connector configuration for database access
- ‚úÖ Ensure Secret Manager secrets are properly injected
- ‚úÖ Check Cloud Run service account has required permissions

**Verification Commands**:
```bash
# Check Cloud Run environment configuration
gcloud run services describe elevia --region=asia-northeast1 --format="yaml" | grep -A 20 "env:"

# Check recent Cloud Run logs for startup errors
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=elevia" --limit=10 --format="table(timestamp,severity,textPayload)" --freshness=10m

# Verify VPC connector is in READY state
gcloud compute networks vpc-access connectors list --region=asia-northeast1

# Test Secret Manager access from Cloud Run service account
gcloud secrets versions access latest --secret=elevia-db-password --impersonate-service-account=elevia-run-sa@$PROJECT_ID.iam.gserviceaccount.com
```

**Common Environment Variable Errors**:
1. **Missing NODE_ENV=production**: Application may not detect Cloud Run environment properly
2. **Missing CLOUD_SQL_CONNECTION_NAME**: Database connection attempts fail
3. **Missing VPC connector configuration**: Cannot reach private Cloud SQL instance
4. **Secret Manager injection failure**: DB_PASS and NEXTAUTH_SECRET remain empty
5. **Incorrect NEXTAUTH_URL**: Authentication redirects fail

**Quick Fix for Deployed Service**:
If a service is already deployed with missing configuration, update it immediately:

```bash
# Get current Cloud SQL connection name
CLOUD_SQL_CONNECTION=$(cd terraform && terraform output -raw cloud_sql_connection_name)

# Update existing Cloud Run service with full configuration
gcloud run services update elevia \
  --region=asia-northeast1 \
  --set-env-vars="NODE_ENV=production,CLOUD_SQL_CONNECTION_NAME=$CLOUD_SQL_CONNECTION,DB_NAME=elevia_db,DB_USER=elevia_user" \
  --set-secrets="DB_PASS=elevia-db-password:latest,NEXTAUTH_SECRET=elevia-nextauth-secret:latest" \
  --vpc-connector=elevia-connector-v2 \
  --vpc-egress=private-ranges-only \
  --service-account=elevia-run-sa@$PROJECT_ID.iam.gserviceaccount.com
```

#### Infrastructure vs Application Deployment Timing

**Issue**: Race condition between infrastructure deployment and application deployment.

**Symptoms**: 
- Application deploys before infrastructure is ready
- Missing Terraform outputs during deployment
- Database connection failures

**Solution**: The deployment workflow includes infrastructure readiness checks:

```yaml
- name: Get Terraform outputs for deployment
  id: tf-outputs
  run: |
    if terraform output cloud_sql_connection_name >/dev/null 2>&1; then
      echo "infrastructure_ready=true" >> $GITHUB_OUTPUT
      CLOUD_SQL_CONNECTION=$(terraform output -raw cloud_sql_connection_name)
      echo "cloud_sql_connection=$CLOUD_SQL_CONNECTION" >> $GITHUB_OUTPUT
    else
      echo "infrastructure_ready=false" >> $GITHUB_OUTPUT
      echo "‚ö†Ô∏è Infrastructure not ready. Deploying without database configuration."
    fi

- name: Deploy to Cloud Run
  run: |
    if [ "${{ steps.tf-outputs.outputs.infrastructure_ready }}" = "true" ]; then
      # Deploy with full configuration
    else
      # Deploy basic service only
    fi
```

**Best Practices**:
- Always check infrastructure readiness before full application deployment
- Deploy basic service first, then update with full configuration
- Use conditional deployment based on Terraform output availability
- Monitor both infrastructure and application workflows for completion

### üîÑ CI/CD Improvement Lessons

Based on real deployment troubleshooting experience, the following improvements have been applied:

#### Configuration Consistency
- **Naming Convention Alignment**: Terraform state bucket naming now consistent between `init.sh` and `deploy.yml`
- **Resource Naming Standards**: All Terraform resources use predictable naming patterns
- **Variable Scope Clarity**: Clear distinction between repository variables and environment secrets

#### Debugging Enhancement
- **Systematic Error Analysis**: Step-by-step debugging approach for CI/CD failures
- **Common Error Patterns**: Documented authentication, permission, and resource issues
- **Prevention Measures**: Proactive checks to avoid common configuration mismatches

#### Deployment Resilience
- **Timeout Management**: 30-minute timeouts for Cloud SQL operations
- **Dependency Management**: Explicit resource dependencies prevent race conditions
- **Error Recovery**: Clear recovery procedures for common deployment failures

#### Future Improvements
Consider implementing these enhancements:
- **Pre-deployment Validation**: Automated checks for configuration consistency
- **Deployment Health Checks**: Post-deployment validation of service functionality
- **Rollback Procedures**: Automated rollback for failed deployments
- **Environment Parity**: Ensure staging environment matches production configuration